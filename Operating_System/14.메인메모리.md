# Main Memory
---
### INDEX
1. 메인메모리
2. MMU
3. MMU의 메모리 보호
4. 메모리 과할당
5. 오버헤드 감소시키는 방법
- 방법 1
- 방법 2
6. 캐시 메모리
7. 캐싱라인

<br>
<br>
<br>


## 메인메모리란
- 메인 메모리는 CPU가 직접 접근할 수 있는 기억장치
- 프로세스 실행하려면 프로그램이 메모리에 올라와야함
- 메인 메모리 : 주소가 할당된 일련의 바이트들로 구성되어있음
- 레지스터가 지시하는데로 CPU는 메모리에 접근해서 다음에 수행할 명령어를 가져옴
- MMU : CPU가 명령어를 수행하는데 필요한 데이터가 없으면, 해당 데이터를 메인메모리로 가져옴. MMU의 역할

## 주기억장치 vs 보조기억장치
- 주기억 장치
  - 메인메모리
  - CPU가 접근할 수 있는 기억장치
  - ROM, RAM, 캐시메모리 ...
 
- 보조기억장치
  - HDD : 하드 디스크 드라이버 약자
  - SSD : 반도체기반의 정보 저장 기억장치

<br>
<br>
<br>

## MMU란
- MMU : Memory Management Unit 메모리 관리 장치
- 논리 주소를 물리 주소로 변환해줌 TLB(논리주소 - 물리주소)를 참조하거나, TLB에 없으면 필요한 데이터를 메인메모리에 가져옴(물리주소 할당, TLB 업데이트)
- 메모리 보호나 캐시 관리 등 CPU가 메모리에 접근하는 걸 총 관리해주는 하드웨어임
- MMU 덕에 가상주소를 통해 물리주소에 접근할 수 있도록 빠른 주소 변환을 도와줌

- MMU가 지원되지 않으면, 물리주소에 직접접근해야 해서 부담될 수 있음
- MMU는 사용자가 기억장소를 일일이 할당해야하는 부담을 줄이고, 그때그때 필요한거만 올리는 데다가 이미 있는건 재할당 굳이 안해줘도 되니깐 프로세스크기가 실제 메모리 욜양을 초과해도 실행할 수 있게 해줌
- 그래서 CPU가 MMU한테 이런 데이터 필요한데 있나 물어보고, 있으면 MMU가 데이터를 찾아서 CPU한테 반환해주고, 없으면 메모리에 할당해서 메인메모리에 올려두고 그걸 반환해주는 듯)
- 캐시
  - CPU가 메인메모리에 직접 접근하는건 비효율적이라 했잖음
  - 상대적으로 CPU는 속도가 빠르고 메인메모리는 속도가 느린데
  - 병목현상
  - 이걸 해결하는데 캐시가 필요함

<br>

## MMU의 메모리 보호
- 프로세스는 독립적인 메모리 공간을 가짐. 자신만 접근 가능
- 프로세스에 합법적으로 접근할 수 있는 주소 영역을 정하고, 만약 잘못 접근하면 trap을 발생시킴. 메모리 보호 할라고.(프로세스 메모리를 말하는지? 메인메모리를 말하는지? 둘다 말하는건지?)
![image](https://github.com/jiyeonnnny/Computer-Science/assets/139419091/6d75fff9-ba90-482d-85ee-818a299fbae6)   
[출처 : https://gyoogle.dev/blog/computer-science/operating-system/Memory.html]   

<br>

- 프로그램 주소 공간이 물리적 메모리에 연속적으로 적재되어있다고 가정하면 이해하기 쉬움
- 해당 프로세스를 실행하려고 CPU에 올려두면, base register값과 limit register값을 재설정해줌
- 물리주소값 = 논리주소값 + base register값(=relocation register값)
- limit register
  - 프로세스를 실행하려고 필요한 데이터를 할당하잖아.
  - 근데 필요한 데이터 그 이상을 할당하면 이상하다고 생각해서 해당 프로세스를 강제 종료하는 역할을 함
  - 다시 말해서, **메모리 보안** 역할을 함
  - 물리주소값이 limit register값보다 작은지 체크하고, 그렇지 않으면 trap을 발생시켜서 프로세스를 강제 종료함
![image](https://github.com/jiyeonnnny/Computer-Science/assets/139419091/d032e6a3-f65a-4c4b-af7e-345d6d43d96c)   
[출처 : https://developer-ping9.tistory.com/43]   

<br>
<br>
<br>

## 메모리 과할당
- 프로세스에 할당된 메모리가, 그 프로세스를 돌릴때 사용하는 실제 메모리 용량보다 더 클때 **메모리 과할당**이라 함
- 보통 **가상메모리**활용해서 사용자가 굳이 신경안써도 알아서 메모리 과할당이 발생하지 않게 괸리해줌
- 근데 사용자가 알만큼 메모리 과할당되는 순간이 있음
  - 프로세스 실행 도중에 페이지 폴트가 발생했을때
  - 페이지 폴트를 발생시킨 페이지 위치를 디스크에 찾음
  - 메모리의 빈 프레임에 페이지를 올려야하는데, 모든 메모리가 사용중이라 빈 프레임이 없음

<br>

- 해결하기 위해 빈 프레임을 확보해야함
  1. 메모리에 올라와 있는 한 프로세스를 종료시켜서 빈 프레임을 얻는 방법
  2. 프로세스 하나를 swap out하고 그 공간을 빈프레임으로 활용하는 방법
 
  - 보통 방법2 을 쓴데
  - 방법1은 사용자들이 눈치채기 쉽다나 뭐라나,
  - 방법1은 느려서 사용자들도 아 메모리가 부족해서, 프로세스를 종료하고, 메모리를 가져오는구나 라는 걸 눈치 채서 안쓴다고 함
  - 방법2는 이전에 했던 페이지 교체인데, 프로세스 하나를 아예 swaping해서, 메모리공간을(프레임을) 바꿔치기한데
 
<br>
<br>
<br>

## 페이지 교체
- 메모리 과할당 발생했을때, 프로세스 하나를 swap out 해서 빈 프레임을 확보하는 방법
- **페이지 교체 과정**
  - 프로세스 실행 도중 페이지(프로레스 실행에 필요한 데이터 일부)가 메인메모리(CPU가 접근할 수 있는 메모리)에 없음
  - 페이지 폴트를 발생시키고 해당 페이지가 저장된 실제 주소를 찾음(혹은 할당함)
  - 메모리에 빈 프레임이 있는 확인함
    - 있으면 해당 프레임에 페이지를 올리고
    - 없으면, victim 프레임을 선정해서 디스크에 기록하고(아마 상태를 저장하는듯) 페이지 테이블을 업데이트함(물리주소를 옮겼으니깐?)
  - 빈프레임에 해당 페이지를 올리고 페이지 테이블을 업데이트함
- 근데 너무 자주 페이지 교체하게 되면 오버헤드 발생함.

<br>

## 오버헤드 감소시키는 해결법
- 빈프레임이 없어서 victim 프레임을 비우고 페이지 교체를 할때는
  1. victim프레임을 비움
  2. 원하는 페이지를 프레임에 올림
  - 2번이나 디스트에 접근함
  - 페이지 교체가 찾아지면 오버헤드가 발생할 수 있음
 
### 방법 1
- **변경 비트**라는 게 있는데 이걸 페이지마다 둠
- victim 페이지가 정해지면(메모리에서 **제거**될 페이지) 해당 페이지의 비트를 확인함
- 해당 비트가 set 상태면, 해당 페이지가 디스크 상의 페이지 내용과 달라졌다는 뜻임
  - 페이지가 메모리에 올라간 후에 수정된 것을 의미함. 그래서 바뀐 내용을 디스크에 저장해야 함
 
- 비트가 clear상태면, 해당 페이지가 디스크 상의 페이지와 동일하다는 뜻임.
- **변경 비트**
  - 페이지 폴트로 인해 victim으로 선정된 해당 페이지가
  - 메모리에 있었을때 수정된 여부를 확인하고
  - 수정된 것만 디스크에 재저장을 해줘서
  - 불필요한 연산을 줄임. 오버헤드 줄임.
 
### 방법 2
- 페이지 교체 알고리즘할때, victim으로 선정할 페이지를 잘 골라야 하는데, 그 알고리즘을 잘 선택하는 거임
- FIFO
- OPT
- LRU
- 그러면 페이지 폴트를 발생할 확률 자체가 현저히 줄어드는 거임


<br>
<br>
<br>

## 캐시메모리
- 아까 **캐시**는 CPU(고속)랑 메인메모리(저속) 사이 속도차로 인한 병목현상을 완화하는 얘라고 했음
- 캐시 메모리란
  - 주기억장치에 저장된 내용 일부를 임시로 저장하는 기억장치
  - CPU가 이미 봤던 걸 재접근할때 ,메모리 참조하고 인출하는 과정을 줄일려고,
  -  캐시 메모리에 데이터를 저장하고 재사용하는 거임
- 캐시는 플리플롭 소자로 구성됨. SRAM으로 되어있어서 DRAM보다 빠름

<br>

### CPU와 주기억장치의 상호작용
- CPU가 접근하고 싶은 메모리의 가상 주소를 전달함
- 캐시 메모리에 해당 메모리가 존재하는지 확인함
- 있으면, 바로 데이터를 CPU에 전달하고
- 없으면, 명령어를 갖고 주기억장치로 접근함
  - 해당 명령어를 가진 데이터를 인출함
  - 해당 명령어 데이터를 캐시에 저장함
  - 해당 명령어를 CPU에 전송함
 
- 이처럼 캐시를 잘 활용하면 연산 혹은 시간이 많이 줄어듬
- 근데 이때, 무작정 캐시에 저장하는게 아니라, 활용도가 높은 거 같은 정보를 담아둬야함
- 적중률을 극대화 하기 위해 지역성 원리를 사용함

<br>

### 지역성
- 기억장치 내 정보를 균일하게 접근하는 게 아니라, 한순간 특정 부분을 집중적으로 참조하는 특성을 **지역성**이라함
- 지역성 2가지 종류
  - 시간 지역성 : 최근 참조된 주소내용을 곧 다음에도 참조하는 특성
  - 공간 지역성 : 실제 프로그램이 참조된 주소와 인접한 주소 내용이 다시 참조되는 특성(완전 이해가 안되는듯)

<br>

## 캐싱 라인
- 빈번하게 사용되는 데이터를 캐시에 저장해도, CPU가 필요로 하는 데이터를 캐시에서 찾을려고, **모든 데이터를 순회**하는 것도 시간 낭비임
- 그니깐, 필요할때 **바로 접근**해서 출력할 수 있어야 캐시가 의미 있음

- **해시테이블** 원리랑 비슷하데
- CPU가 원하는 데이터가 캐시에 있을때, 해당 데이터를 캐시메모리에서 바로 찾을 수 있게, 해시테이블 보고 바로 반환하는 거 처럼 작동한데
- 근데 이 캐싱라인도 여러 종류가 있는데, direct mapped, fully associative, set assosciative...이 있데
